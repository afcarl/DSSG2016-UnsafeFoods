{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text Mining Amazon Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A major component of our research has been text mining the actual Amazon reviews. Our hope for our analysis was to find trends and relationships that could help us discern some relationship between the reviews' natural language and the likelihood of a recall. This is a complex research topic, not only due to the nature of computational linguistics but also because of the diversity in nature and severity of recalls. \n",
    "\n",
    "For a preliminary analysis, we can fetch some of the reviews and perform a sentiment analysis to better understand the text. For the bulk of our natural language analyses and text preprocessing, we utilized the [NLTK Python module](http://www.nltk.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "import nltk.classify.util\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Connect to database using your credentials\n",
    "conn = psycopg2.connect(database=<db name>, user=<user name>, password=<password>, host=<host>, port=\"5432\")\n",
    "\n",
    "print(\"Opened database successfully\")\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Fetch a sample of recall reviews and non recall reviews\n",
    "'''\n",
    "cur.execute('Select review_text from review where product_id in (select product_id from recalledproduct)\\\n",
    "            order by random() limit 500;')\n",
    "\n",
    "review_texts_recall = pd.DataFrame(cur.fetchall())\n",
    "review_texts_recall = review_texts_recall[0]\n",
    "\n",
    "cur.execute('Select review_text from review where product_id not in (select product_id from recalledproduct)\\\n",
    "            order by random() limit 500;')\n",
    "\n",
    "review_texts_no_recall = pd.DataFrame(cur.fetchall())\n",
    "review_texts_no_recall = review_texts_no_recall[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the text.\n",
    "'''\n",
    "\n",
    "#remove special characters, numbers, etc.\n",
    "import re #regular expressions module in Python\n",
    "\n",
    "review_texts_recall = [re.sub('[^a-zA-Z\\s]', ' ',review_texts_recall[i]) for i in range(len(review_texts_recall))]\n",
    "review_texts_no_recall = [re.sub('[^a-zA-Z\\s]', ' ',review_texts_no_recall[i]) for i in range(len(review_texts_no_recall))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Tokenize the text. NOTE: In NLTK you have to run nltk.download() to run the download client. From\n",
    "here you will be able to select 'punkt' which gives you access to the NLTK word tokenizer method \n",
    "as seen below.\n",
    "'''\n",
    "from nltk import word_tokenize\n",
    "\n",
    "tokens_recall = [word_tokenize(review) for review in review_texts_recall]\n",
    "tokens_no_recall = [word_tokenize(review) for review in review_texts_no_recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Custom methods to split on uppercase letters and then make all lowercase\n",
    "'''\n",
    "\n",
    "#split words on uppercase letters\n",
    "def split_uppercase(tokens):\n",
    "    tokens_II = np.empty((len(tokens),0)).tolist()\n",
    "    for review in tokens:\n",
    "        n = tokens.index(review)\n",
    "        for word in review:\n",
    "            split = re.sub(r'([A-Z][a-z])', r' \\1', word)\n",
    "            tokens_II[n].append(split)\n",
    "    return tokens_II\n",
    "\n",
    "tokens_recall = split_uppercase(tokens_recall)\n",
    "tokens_no_recall = split_uppercase(tokens_no_recall)\n",
    "\n",
    "\n",
    "##Make all text lower case\n",
    "def make_lowercase(tokens):\n",
    "    tokens_final = np.empty((len(tokens),0)).tolist()\n",
    "    for review in tokens:\n",
    "        n = tokens.index(review)\n",
    "        for word in review:\n",
    "            lowercase_word = word.lower()\n",
    "            tokens_final[n].append(lowercase_word)\n",
    "    return tokens_final\n",
    "\n",
    "tokens_recall = make_lowercase(tokens_recall)\n",
    "tokens_no_recall = make_lowercase(tokens_no_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Stem words and remove stopwords- nltk.download('stopwords')\n",
    "'''\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "st = LancasterStemmer()\n",
    "\n",
    "##Remove stopwords and stem\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    stemmed_token = np.empty((len(tokens),0)).tolist()\n",
    "    for review in tokens:\n",
    "        n = tokens.index(review)\n",
    "        for word in review:\n",
    "            if word not in stopwords:\n",
    "                stem = st.stem(word)\n",
    "                stemmed_token[n].append(stem)\n",
    "    return stemmed_token\n",
    "        \n",
    "tokens_recall = stem_tokens(tokens_recall)\n",
    "tokens_no_recall = stem_tokens(tokens_no_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have processed and tokenized the texts, we can apply our analyses to the corpora. For this exercise, we will go through a simple classification model and then fetch testing data from the DB to see how our sentiment analysis fares in predictive analysis. You can see this exercise in more depth at the [sentiment analysis](http://www.nltk.org/howto/sentiment.html) page on nltk.org. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a list of training docs, each with their corresponding tag- recall or no recall\n",
    "recall_docs = [[recall_doc, 'recall'] for recall_doc in tokens_recall]\n",
    "no_recall_docs = [[no_recall_doc, 'no recall'] for no_recall_doc in tokens_no_recall]\n",
    "\n",
    "recall_train = recall_docs[:int(len(review_texts_recall)/2)]\n",
    "recall_test = recall_docs[int(len(review_texts_recall)/2):len(review_texts_recall)]\n",
    "no_recall_train = no_recall_docs[:int(len(review_texts_no_recall)/2)]\n",
    "no_recall_test = no_recall_docs[int(len(review_texts_no_recall)/2):len(review_texts_recall)]\n",
    "docs_train = recall_train + no_recall_train\n",
    "docs_test = recall_test + no_recall_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17146"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create sentiment analyzer from nltk package\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "\n",
    "#handle negation for situations like 'not amazing'\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc[0]) for doc in docs_train])\n",
    "len(all_words_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#perform sentiment analysis with unigrams (single tokens) handling the negations\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select features to extract. For this analysis with will use unigram features.\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply the features to training and testing set\n",
    "training_set = sentim_analyzer.apply_features(docs_train)\n",
    "testing_set = sentim_analyzer.apply_features(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "#Create the Naive Bayes classifier and perform classification on the texts\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.71\n",
      "F-measure [no recall]: 0.7216890595009597\n",
      "F-measure [recall]: 0.6972860125260961\n",
      "Precision [no recall]: 0.6937269372693727\n",
      "Precision [recall]: 0.7292576419213974\n",
      "Recall [no recall]: 0.752\n",
      "Recall [recall]: 0.668\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(sentim_analyzer.evaluate(testing_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Your Queries for Your Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we can make our query more specific to handle the time of the review versus the time of the recall, and also let's go ahead and tag based not just on whether the product was reclled but also the classification of the recall (Class I, II or III). \n",
    "\n",
    "While this updated method might somewhat improve results, it could still be made much more accurate. One problem worth addressing is the fact that many of the reviews associated with a recall are not negative at all and should not indicate whether it should be recalled. Therefore, it would make sense to further explore how to alter the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n",
      "(500, 2)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This query selects reviews made within a year of the recall, and also tags them with their classification. Moreover,\n",
    "it randomly selects 500 rather than just the first 500, so that it is not dependent on the order in which the items were added.\n",
    "'''\n",
    "cur.execute('SELECT rv.review_text, rv.product_id from review rv \\\n",
    "            join recalledproduct rp on rv.product_id = rp.product_id\\\n",
    "            join recall rc on rp.recall_id = rc.recall_id\\\n",
    "            join event e on rc.event_id = e.event_id where \\\n",
    "            @ (date_part(\\'month\\',TIMESTAMP \\'epoch\\' + rv.unix_review_time * INTERVAL \\'1 second\\')\\\n",
    "            - date_part(\\'month\\', e.initiation_date)) <= 12 \\\n",
    "            order by random() limit 500;')\n",
    "\n",
    "specified_recall = pd.DataFrame(cur.fetchall())\n",
    "\n",
    "cur.execute('SELECT rv.review_text from review rv \\\n",
    "            where rv.product_id not in (\\\n",
    "            select distinct product_id from recalledproduct)\\\n",
    "            order by random() limit 500;')\n",
    "\n",
    "specified_no_recall = pd.DataFrame(cur.fetchall())\n",
    "specified_no_recall['Classification'] = ['No Recall'] * specified_no_recall.shape[0]\n",
    "\n",
    "print(specified_recall.shape)\n",
    "print(specified_no_recall.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall_text = specified_recall.iloc[:,0]\n",
    "no_recall_text = specified_no_recall.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the text.\n",
    "'''\n",
    "#remove special characters, numbers, etc.\n",
    "review_texts_recall = [re.sub('[^a-zA-Z\\s]', ' ',recall_text[i]) for i in range(len(recall_text))]\n",
    "review_texts_no_recall = [re.sub('[^a-zA-Z\\s]', ' ',no_recall_text[i]) for i in range(len(no_recall_text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Tokenize the text.\n",
    "'''\n",
    "tokens_recall = [word_tokenize(review) for review in review_texts_recall]\n",
    "tokens_no_recall = [word_tokenize(review) for review in review_texts_no_recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Custom methods to split on uppercase letters and then make all lowercase\n",
    "'''\n",
    "\n",
    "#split words on uppercase letters\n",
    "tokens_recall = split_uppercase(tokens_recall)\n",
    "tokens_no_recall = split_uppercase(tokens_no_recall)\n",
    "\n",
    "##Make all text lower case\n",
    "tokens_recall = make_lowercase(tokens_recall)\n",
    "tokens_no_recall = make_lowercase(tokens_no_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Stem words and remove stopwords- nltk.download('stopwords')\n",
    "'''\n",
    "##Remove stopwords and stem using the previously defined Lancaster stemmer\n",
    "tokens_recall = stem_tokens(tokens_recall)\n",
    "tokens_no_recall = stem_tokens(tokens_no_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a list of training docs, each with their corresponding tag- recall or no recall\n",
    "#This can be updated so that the tags are specified on the classification as fetched in \n",
    "#the more advanced query above. For these purposes, we will just replicate the above experiment\n",
    "#to analyze the difference in the success of the Naive Bayes model after optimizing the\n",
    "#query for our analysis.\n",
    "recall_docs = [[recall_doc, 'recall'] for recall_doc in tokens_recall]\n",
    "no_recall_docs = [[no_recall_doc, 'no recall'] for no_recall_doc in tokens_no_recall]\n",
    "\n",
    "half_index_r = int(len(recall_docs)/2)\n",
    "whole_index_r = len(recall_docs)\n",
    "half_index_nr = int(len(no_recall_docs)/2)\n",
    "whole_index_nr = len(no_recall_docs)\n",
    "\n",
    "recall_train = recall_docs[:half_index_r]\n",
    "recall_test = recall_docs[half_index_r:whole_index_r]\n",
    "no_recall_train = no_recall_docs[:half_index_nr]\n",
    "no_recall_test = no_recall_docs[half_index_nr:whole_index_nr]\n",
    "docs_train = recall_train + no_recall_train\n",
    "docs_test = recall_test + no_recall_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15761"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create sentiment analyzer from nltk package\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "\n",
    "#handle negation for situations like 'not amazing'\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc[0]) for doc in docs_train])\n",
    "len(all_words_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#perform sentiment analysis with unigrams (single tokens) handling the negations\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract features\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply the features to training and testing set\n",
    "training_set = sentim_analyzer.apply_features(docs_train)\n",
    "testing_set = sentim_analyzer.apply_features(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "#Create the Naive Bayes classifier and perform classification on the texts\n",
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.666\n",
      "F-measure [no recall]: 0.5876543209876542\n",
      "F-measure [recall]: 0.719327731092437\n",
      "Precision [no recall]: 0.7677419354838709\n",
      "Precision [recall]: 0.6202898550724638\n",
      "Recall [no recall]: 0.476\n",
      "Recall [recall]: 0.856\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(sentim_analyzer.evaluate(testing_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
